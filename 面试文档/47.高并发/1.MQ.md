## [Why MQ](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/why-mq.md) 
### 优点
使用场景：<font color=red>解耦，异步，削峰</font>
> 解耦： 通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。

### 缺点
> 1. <font color=red>系统可用性降低：</font>系统引入的外部依赖越多，则越容易挂掉，维护程度较高，需要<font color=red>[考虑消息队列的高可用](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md) </font>
> 2. <font color=red>系统复杂性提高：</font>需要<font color=red>[确保消息没有重复消费](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed.md)</font>，<font color=red>[消息丢失的情况](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md)</font>
> 3. <font color=red>数据一致性问题：</font>，比如A系统处理完成后， 订阅的三个系统ABC，AB成功处理， C处理失败，怎么处理？保证数据的一致性

### MQ选型
> 1. ActiveMQ 没有经过大规模的<font color=red>吞吐量验证</font>，社区不是很活跃
> 2. RabbitMQ, 开源，社区活跃，消息可靠性比较高，基于Erlang 开发， 并发能力很强，延时很低
> 3. RocketMQ, 阿里出品，需要有较强的基础架构研发团队实力

### 高可用
1. 如何保证消息的可靠性传输（如何处理数据的丢失问题）
> <font color=red>MQ的一个基本原则：数据不能多一条也不能少一条</font>
> 数据丢失，存在如下两种情况：
> 1. 生产者丢失数据：也就是说数据还没有到达MQ的时候， 半路丢失，因为网络等原因丢失
> 2. 解决这个问题有如下两种方法：
> 2.1 里
![](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/rabbitmq-message-lose-solution.png)

### 消息队列延时（数据挤压，丢失）
1. 消费端出现问题， 消费的速度及其慢（DB Mysql 出现挂了或者延时非常大，造成MQ的消费积压）
> <font color=red>解决方案：</font>
> 1.修复 <font color=red>consumer</font>的问题，确保其能恢复速度消费
> 2. 停止掉现有的 <font color=red>consumer</font>
> 3. 新建一个 <font color=red>topic</font>,  <font color=red>partition</font>是原来的10倍， <font color=red>临时</font>建立好原先10倍的queue数量
> 4. 临时写一个 <font color=red>分发数据的consumer</font>程序，部署这个临时程序去消费挤压的数据，消费时不做耗时操作，直接均匀轮训写入临时建立好的10数量的queue
> 5.  <font color=red>直接扩容</font>10倍的机器来部署 <font color=red>consumer</font>,每一个consumer消费一个临时的queue数据
> 6. 消费挤压的数据后，再次恢复原先的部署架构，重新用原来的 <font color=red>consumer</font>机器架构来进行正常消费

2. 消息挤压后，造成MQ消息过期失效
>  <font color=red>RabbitMQ 是可以设置过期时间TTL</font>，如果消息挤压一定的时间后， MQ会自动清理过期的数据， 这个数据就丢失了
>  <font color=red>解决方案：</font>
> 1. 当数据大量挤压， 数据改丢失还是丢失，也就是直接丢弃数据
> 2. 高峰期过后，我们写个 <font color=red>批量数据清理</font>临时程序，再次将丢失的数据推送到MQ重新进行消费

3. 如果大量消息积压在MQ， MQ写满了怎么办？
> 第一个方案还是没来得及处理数据，造成了MQ写满了 只能写一个丢一个，然后用上面第二个方案，进行数据弥补，在高峰过后，重新推送处理数据丢失的数据

### 处理消息挤压的常规操作
1. 提高消费的 <font color=red>并行度</font>，通过怎叫消费并行度，来提高吞吐量，但是并不是并行度越高越好， 达到一定的程度，并行度反而会降低
> 1. 设置一个 <font color=red>ConsumerGroup</font>(分组机制)，通过提高 <font color=red>Consumer 实例</font>来提供并行度
> 2. 通过扩容机器，或者启用已有机器的多进程来进行处理

2.  <font color=red>批量方式进行消费</font>：对于可以进行批量操作的业务数据，进行批量处理，比如说一个处理耗1s,10个处理耗时也不过2s
3.  消息达到一定的挤压阈值，启用<font color=red>跳过非重要消息</font>机制，也就是有限处理重要数据，如订单数据，付款数据等，其他的非重要数据延后处理
4. <font color=red>优化每条消息的消费过程：</font>比如说一条消息需要进行4次DB操作， 看尽量优化代码逻辑，较少操作次数和耗时操作